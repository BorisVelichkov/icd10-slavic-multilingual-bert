{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '..\\\\data\\\\'\n",
    "ORIGINAL_BASE_PATH = '..\\\\data\\\\original\\\\'\n",
    "DIR_SEPARATOR = '\\\\' # /\n",
    "\n",
    "LABEL_COLUMN = 'ICD10'\n",
    "TEXT_COLUMN = 'Text'\n",
    "PRED_CLASS = 'pred_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '{0}train-4.csv'.format(BASE_PATH)\n",
    "train_df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '{0}test-4.csv'.format(BASE_PATH)\n",
    "test_df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '{0}dev-4.csv'.format(BASE_PATH)\n",
    "dev_df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[TEXT_COLUMN] = train_df[TEXT_COLUMN].apply(lambda x:  str(x))\n",
    "dev_df[TEXT_COLUMN] = dev_df[TEXT_COLUMN].apply(lambda x:  str(x))\n",
    "test_df[TEXT_COLUMN] = test_df[TEXT_COLUMN].apply(lambda x:  str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_df[TEXT_COLUMN].to_numpy()\n",
    "test_array = test_df[TEXT_COLUMN].to_numpy()\n",
    "dev_array = dev_df[TEXT_COLUMN].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_test = np.intersect1d(test_array, train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_dev = np.intersect1d(dev_array, train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407735786323839"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection_test)/len(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406173910609835"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection_dev)/len(dev_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>аутоиммун полиендокринопат синдром</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>затлъстяван недостиг рецептор меланокорти 4</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>уточн кист уст кухин некласифицира другад</td>\n",
       "      <td>3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oris resolutio n tia</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тиф причин треск класическ</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text  pred_class\n",
       "0           аутоиммун полиендокринопат синдром        1501\n",
       "1  затлъстяван недостиг рецептор меланокорти 4        1562\n",
       "2    уточн кист уст кухин некласифицира другад        3098\n",
       "3                         oris resolutio n tia        2402\n",
       "4                   тиф причин треск класическ         264"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nlpaug in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (0.0.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (1.18.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (45.2.0.post20200210)\n",
      "Requirement already satisfied: requests in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sylvia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug numpy matplotlib python-dotenv setuptools requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as nacw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map bg to en keyboard in order to use the nlp aug keyboard augmenter\n",
    "def keyboard_mapping(word, direction):\n",
    "    bg_en_map = { 'а':'a', 'б':'b', 'в':'w', 'г':'g', 'д':'d', 'е':'e', 'ж':'v', \n",
    "                 'з':'z', 'и':'i', 'й':'j', 'к':'k', 'л':'l', 'м':'m', 'н':'n', 'о':'o', 'п':'p', 'р':'r',\n",
    "                 'с':'s', 'т':'t', 'у':'u', 'ф':'f', 'х':'h', 'ц':'c', 'ч':'`', 'ш':'[', 'щ':']', 'ъ':'y',\n",
    "                 'ь':'x', 'ю':'\\\\', 'я':'q',\n",
    "                 'А':'A', 'Б':'B', 'В':'W', 'Г':'G', 'Д':'D', 'Е':'E', 'Ж':'V', \n",
    "                 'З':'Z', 'И':'I', 'Й':'J', 'К':'K', 'Л':'L', 'М':'M', 'Н':'N', 'О':'O', 'П':'P', 'Р':'R',\n",
    "                 'С':'S', 'Т':'T', 'Ъ':'U', 'Ф':'F', 'Х':'H', 'Ц':'C', 'Ч':'~', 'Ш':'{', 'Щ':'}', 'Ъ':'Y',\n",
    "                 'ѝ':'X', 'Ю':'|', 'Я':'Q'}\n",
    "    \n",
    "    en_bg_map = {v: k for k, v in bg_en_map.items()}\n",
    "    result = ''\n",
    "    \n",
    "    current_map = bg_en_map if direction == 1 else en_bg_map\n",
    "    \n",
    "    for character in word:        \n",
    "        # handle non-mapped characters\n",
    "        if character in current_map:\n",
    "            result += current_map[character]\n",
    "        else:\n",
    "            result += character\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def augment_text(text):\n",
    "  aug_char = [\n",
    "      nac.RandomCharAug(action=\"swap\", aug_char_min=1, min_char=1),\n",
    "      nac.RandomCharAug(action=\"delete\", aug_char_min=1, min_char=1),\n",
    "      nac.KeyboardAug(aug_char_max=1, min_char=1, include_special_char=False, include_numeric=False)\n",
    "  ]\n",
    "\n",
    "  aug_word = [ \n",
    "      nacw.RandomWordAug(action=\"swap\"),\n",
    "      nac.RandomCharAug(action=\"swap\", aug_char_min=1, min_char=1)\n",
    "  ]\n",
    "  tokens = text.split(' ')\n",
    "  tokens_len = len(tokens)\n",
    "  \n",
    "  augmented_text = text\n",
    "    \n",
    "  if len(text) == 1:\n",
    "    augmented_text = text\n",
    "  elif tokens_len == 1:\n",
    "      aug_number = random.randint(0, 2)\n",
    "      if aug_number == 2: #keyboard        \n",
    "        transliterated = keyboard_mapping(text, 1)\n",
    "        augmented_transliterated = aug_char[aug_number].augment(transliterated)\n",
    "        augmented_text = keyboard_mapping(augmented_transliterated, 2)\n",
    "      else:\n",
    "        augmented_text = aug_char[aug_number].augment(text)\n",
    "  else:\n",
    "    aug_number = random.randrange(2)\n",
    "    if aug_number == 1:\n",
    "      random_word_number = random.randint(0, tokens_len-1)\n",
    "      random_word = tokens[random_word_number]\n",
    "        \n",
    "      i = 1\n",
    "      while len(random_word) < 2 and i < 10:\n",
    "        random_word_number = random.randint(0, tokens_len-1)\n",
    "        random_word = tokens[random_word_number]\n",
    "        i += 1\n",
    "        \n",
    "      if len(random_word) >= 2:\n",
    "          try: \n",
    "              augmented_word = aug_word[aug_number].augment(random_word)\n",
    "              tokens[random_word_number] = augmented_word\n",
    "              augmented_text = ' '.join(tokens)\n",
    "          except:\n",
    "            print(random_word)\n",
    "      else:\n",
    "        augmented_text = aug_word[0].augment(text)\n",
    "    else:        \n",
    "      augmented_text = aug_word[aug_number].augment(text)\n",
    "\n",
    "  if augmented_text == text:\n",
    "    augmented_text = aug_char[1].augment(augmented_text)\n",
    "\n",
    "  return augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'атз'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_text('таз')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = pd.DataFrame({\n",
    "        TEXT_COLUMN:test_df[TEXT_COLUMN].apply(lambda x: augment_text(x) if x in intersection_test else x),\n",
    "        PRED_CLASS:test_df[PRED_CLASS],\n",
    "        'OLD_TEXT':test_df[TEXT_COLUMN]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_array = new_test_df[TEXT_COLUMN].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_new_test = np.intersect1d(new_test_array, train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005098082677601684"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection_new_test)/len(new_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df.to_csv('{0}new-test-4.csv'.format(BASE_PATH), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev_df = pd.DataFrame({\n",
    "        TEXT_COLUMN:dev_df[TEXT_COLUMN].apply(lambda x: augment_text(x) if x in intersection_dev else x),\n",
    "        PRED_CLASS:dev_df[PRED_CLASS],\n",
    "        'OLD_TEXT':dev_df[TEXT_COLUMN]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev_array = new_dev_df[TEXT_COLUMN].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_new_dev = np.intersect1d(new_dev_array, train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005093616187624192"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection_new_dev)/len(new_dev_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev_df.to_csv('{0}new-dev-4.csv'.format(BASE_PATH), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
